{"nbformat_minor": 0, "nbformat": 4, "cells": [{"source": ["## Le r\u00e9seau de neurones al\u00e9atoire\n", "\n", "Afin de ne pas avoir \u00e0 faire face \u00e0 de nombreuses difficult\u00e9s \u00e0 la fois, il convient de d\u00e9velopper et d'\u00e9tudier le mod\u00e8le de d\u00e9tection d'orientation \u00e9tape par \u00e9tape. Ainsi, avant de traiter le r\u00e9seau en Ring, une g\u00e9n\u00e9ralisation de celui-ci, le r\u00e9seau al\u00e9atoire ou \"random neural network\" (RNN), est d'abord d\u00e9velopp\u00e9e et explor\u00e9e. Cette \u00e9tape permet, dans un premier temps, de n\u00e9gliger la topologie du r\u00e9seau pour se concentrer sur la connectique ainsi que sur la recherche et d\u00e9monstration d'un \u00e9tat d'\u00e9quilibre de celui-ci. \n", "\n", "Le RNN utilis\u00e9 est un r\u00e9seau comportant mille neurones propres au r\u00e9seau et cinq cents neurones pour la source, et est constitu\u00e9 de trois populations: une population source, une population excitatrice et une population inhibitrice. La population source mise \u00e0 part, le r\u00e9seau contient des neurones du m\u00eame type que ceux utilis\u00e9s dans le r\u00e9seau feedforward \u00e9tudi\u00e9 jusqu'\u00e0 pr\u00e9sent.\n", "\n", "D\u00e8s \u00e0 pr\u00e9sent, nous parlons de \"connexion\" pour d\u00e9signer une connexion synaptique entre neurones, et de \"projection\" lorsque nous faisons r\u00e9f\u00e9rence \u00e0 l'ensemble des connexions des neurones d'une population A aux neurones d'une autre population B. Le poids d'une projection, est alors le poids de toutes les connexions synaptiques de cette projection.\n", "Aussi le RRNN se d\u00e9cline sous deux formes :\n", "- une forme feed-forward dans laquelle seules les populations source et exitatrice sont connect\u00e9es.\n", "- une forme r\u00e9currente appel\u00e9e \"random recurrent neural network\" (RRNN)\n", "\n", "Dans ces deux formes du r\u00e9seau, la population source comporte des neurones qui d\u00e9chargent selon un processus de Poisson homog\u00e8ne. La population excitatrice, E, re\u00e7oit l'activit\u00e9 \u00e9mise par la source via une projection de type \"one to one\". C'est-\u00e0-dire que chaque neurone de la population source est connect\u00e9 \u00e0 un seul neurone de la population E. Dans un RRNN, l'activit\u00e9 transform\u00e9e par cette derni\u00e8re excite la population inhibitrice. Et, la population inhibitrice, I, dont les neurones poss\u00e8dent, hormis leur facult\u00e9 d'inhibition, les m\u00eames propri\u00e9t\u00e9s que les neurones excitateurs, inhibe E. En outre, E et I poss\u00e8dent des connexions r\u00e9currentes et de fa\u00e7on arbitraire (car on peut r\u00e9gler les poids d'interaction), les populations E et I poss\u00e8dent le m\u00eame nombre de neurones <cite data-cite=\"Brunel2000\">(Brunel, 2000)</cite>."], "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": [], "outputs": [], "metadata": {"collapsed": true}}], "metadata": {"kernelspec": {"display_name": "Python 2", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python", "file_extension": ".py", "version": "2.7.12", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}}}